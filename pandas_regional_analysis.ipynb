{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae705c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"regional_sales.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e9278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (8, 5)\n",
      "\n",
      "First few rows:\n",
      "   order_id region   product  quantity  price\n",
      "0      2001  North  Keyboard       2.0   1500\n",
      "1      2002  South     Mouse       1.0    500\n",
      "2      2003  North   Monitor       1.0  12000\n",
      "3      2004   East     Mouse       4.0    500\n",
      "4      2005   West  Keyboard       1.0   1500\n",
      "\n",
      "Data Types:\n",
      "order_id      int64\n",
      "region          str\n",
      "product         str\n",
      "quantity    float64\n",
      "price         int64\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "order_id    0\n",
      "region      0\n",
      "product     0\n",
      "quantity    1\n",
      "price       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "311bdc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 8\n",
      "Rows after cleaning: 7\n"
     ]
    }
   ],
   "source": [
    "clean_df = df.dropna(subset=[\"quantity\"])\n",
    "print(f\"Rows before cleaning: {len(df)}\")\n",
    "print(f\"Rows after cleaning: {len(clean_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a468f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"quantity\"] = pd.to_numeric(clean_df[\"quantity\"], errors='coerce')\n",
    "clean_df[\"price\"] = pd.to_numeric(clean_df[\"price\"], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453fc4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates_before = clean_df.duplicated().sum()\n",
    "clean_df = clean_df.drop_duplicates()\n",
    "print(f\"Duplicates removed: {duplicates_before}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6305accd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset:\n",
      "   order_id region   product  quantity  price\n",
      "0      2001  North  Keyboard       2.0   1500\n",
      "1      2002  South     Mouse       1.0    500\n",
      "2      2003  North   Monitor       1.0  12000\n",
      "3      2004   East     Mouse       4.0    500\n",
      "4      2005   West  Keyboard       1.0   1500\n",
      "6      2007   East  Keyboard       3.0   1500\n",
      "7      2008   West     Mouse       2.0    500\n",
      "\n",
      "Missing values after cleaning:\n",
      "order_id    0\n",
      "region      0\n",
      "product     0\n",
      "quantity    0\n",
      "price       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCleaned Dataset:\")\n",
    "print(clean_df)\n",
    "print(f\"\\nMissing values after cleaning:\\n{clean_df.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b10fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with revenue:\n",
      "   order_id region  quantity  price  revenue\n",
      "0      2001  North       2.0   1500   3000.0\n",
      "1      2002  South       1.0    500    500.0\n",
      "2      2003  North       1.0  12000  12000.0\n",
      "3      2004   East       4.0    500   2000.0\n",
      "4      2005   West       1.0   1500   1500.0\n",
      "6      2007   East       3.0   1500   4500.0\n",
      "7      2008   West       2.0    500   1000.0\n"
     ]
    }
   ],
   "source": [
    "clean_df[\"revenue\"] = clean_df[\"quantity\"] * clean_df[\"price\"]\n",
    "print(\"Dataset with revenue:\")\n",
    "print(clean_df[[\"order_id\", \"region\", \"quantity\", \"price\", \"revenue\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a09b32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regional Summary:\n",
      "  Region  Total_Revenue  Total_Quantity\n",
      "0   East         6500.0             7.0\n",
      "1  North        15000.0             3.0\n",
      "2  South          500.0             1.0\n",
      "3   West         2500.0             3.0\n"
     ]
    }
   ],
   "source": [
    "regional_summary = clean_df.groupby(\"region\").agg({\n",
    "    \"revenue\": \"sum\",\n",
    "    \"quantity\": \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "regional_summary.columns = [\"Region\", \"Total_Revenue\", \"Total_Quantity\"]\n",
    "print(\"\\nRegional Summary:\")\n",
    "print(regional_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf45d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-Performing Region:\n",
      "Region: North\n",
      "Total Revenue: 15,000.00\n"
     ]
    }
   ],
   "source": [
    "top_region = regional_summary.sort_values(\"Total_Revenue\", ascending=False).iloc[0]\n",
    "print(f\"\\nTop-Performing Region:\")\n",
    "print(f\"Region: {top_region['Region']}\")\n",
    "print(f\"Total Revenue: {top_region['Total_Revenue']:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8630b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regions Sorted by Revenue (High to Low):\n",
      "  Region  Total_Revenue  Total_Quantity\n",
      "1  North        15000.0             3.0\n",
      "0   East         6500.0             7.0\n",
      "3   West         2500.0             3.0\n",
      "2  South          500.0             1.0\n"
     ]
    }
   ],
   "source": [
    "regional_summary_sorted = regional_summary.sort_values(\"Total_Revenue\", ascending=False)\n",
    "print(\"\\nRegions Sorted by Revenue (High to Low):\")\n",
    "print(regional_summary_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb55a3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Low-Performing Regions (Revenue < 5,000):\n",
      "  Region  Total_Revenue  Total_Quantity\n",
      "2  South          500.0             1.0\n",
      "3   West         2500.0             3.0\n"
     ]
    }
   ],
   "source": [
    "low_performing = regional_summary[regional_summary[\"Total_Revenue\"] < 5000]\n",
    "print(\"\\nLow-Performing Regions (Revenue < 5,000):\")\n",
    "print(low_performing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71cef408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: regional_revenue_summary.csv\n"
     ]
    }
   ],
   "source": [
    "regional_summary_sorted.to_csv(\"regional_revenue_summary.csv\", index=False)\n",
    "print(\"Saved: regional_revenue_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28057818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: low_performing_regions.csv\n"
     ]
    }
   ],
   "source": [
    "if len(low_performing) > 0:\n",
    "    low_performing.to_csv(\"low_performing_regions.csv\", index=False)\n",
    "    print(\"Saved: low_performing_regions.csv\")\n",
    "else:\n",
    "    print(\"No low-performing regions found (all regions above threshold)\")\n",
    "    # Create empty file with headers\n",
    "    pd.DataFrame(columns=[\"Region\", \"Total_Revenue\", \"Total_Quantity\"]).to_csv(\n",
    "        \"low_performing_regions.csv\", index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b6a5d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analysis Summary ===\n",
      "Total Regions Analyzed: 4\n",
      "Total Revenue Across All Regions: 24,500.00\n",
      "Average Revenue per Region: 6,125.00\n",
      "Top Region: North (15,000.00)\n",
      "Low-Performing Regions: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Analysis Summary ===\")\n",
    "print(f\"Total Regions Analyzed: {len(regional_summary)}\")\n",
    "print(f\"Total Revenue Across All Regions: {regional_summary['Total_Revenue'].sum():,.2f}\")\n",
    "print(f\"Average Revenue per Region: {regional_summary['Total_Revenue'].mean():,.2f}\")\n",
    "print(f\"Top Region: {top_region['Region']} ({top_region['Total_Revenue']:,.2f})\")\n",
    "print(f\"Low-Performing Regions: {len(low_performing)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f972bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_regional_sales(input_file, revenue_threshold=5000):\n",
    "    \"\"\"\n",
    "    Analyze regional sales performance and generate insights.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the sales CSV file\n",
    "        revenue_threshold (float): Threshold for low-performing regions\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (regional_summary, low_performing_regions)\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(\"Step 1: Dataset loaded\")\n",
    "    \n",
    "    # Clean data\n",
    "    clean_df = df.dropna(subset=[\"quantity\"])\n",
    "    clean_df[\"quantity\"] = pd.to_numeric(clean_df[\"quantity\"], errors='coerce')\n",
    "    clean_df[\"price\"] = pd.to_numeric(clean_df[\"price\"], errors='coerce')\n",
    "    clean_df = clean_df.drop_duplicates()\n",
    "    print(\"Step 2: Data cleaned\")\n",
    "    \n",
    "    # Compute revenue\n",
    "    clean_df[\"revenue\"] = clean_df[\"quantity\"] * clean_df[\"price\"]\n",
    "    print(\"Step 3: Revenue calculated\")\n",
    "    \n",
    "    # Aggregate by region\n",
    "    regional_summary = clean_df.groupby(\"region\").agg({\n",
    "        \"revenue\": \"sum\",\n",
    "        \"quantity\": \"sum\"\n",
    "    }).reset_index()\n",
    "    regional_summary.columns = [\"Region\", \"Total_Revenue\", \"Total_Quantity\"]\n",
    "    regional_summary = regional_summary.sort_values(\"Total_Revenue\", ascending=False)\n",
    "    print(\"Step 4: Regional aggregations computed\")\n",
    "    \n",
    "    # Identify low-performing regions\n",
    "    low_performing = regional_summary[regional_summary[\"Total_Revenue\"] < revenue_threshold]\n",
    "    print(\"Step 5: Key insights identified\")\n",
    "    \n",
    "    # Generate outputs\n",
    "    regional_summary.to_csv(\"regional_revenue_summary.csv\", index=False)\n",
    "    if len(low_performing) > 0:\n",
    "        low_performing.to_csv(\"low_performing_regions.csv\", index=False)\n",
    "    else:\n",
    "        pd.DataFrame(columns=[\"Region\", \"Total_Revenue\", \"Total_Quantity\"]).to_csv(\n",
    "            \"low_performing_regions.csv\", index=False\n",
    "        )\n",
    "    print(\"Step 6: Output files generated\")\n",
    "    \n",
    "    # Display insights\n",
    "    top_region = regional_summary.iloc[0]\n",
    "    print(\"\\n=== Key Insights ===\")\n",
    "    print(f\"Top-Performing Region: {top_region['Region']} (Revenue: {top_region['Total_Revenue']:,.2f})\")\n",
    "    print(f\"Low-Performing Regions: {len(low_performing)}\")\n",
    "    if len(low_performing) > 0:\n",
    "        print(\"Regions needing attention:\")\n",
    "        for _, row in low_performing.iterrows():\n",
    "            print(f\"  - {row['Region']}: {row['Total_Revenue']:,.2f}\")\n",
    "    \n",
    "    return regional_summary, low_performing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "544bc1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Dataset loaded\n",
      "Step 2: Data cleaned\n",
      "Step 3: Revenue calculated\n",
      "Step 4: Regional aggregations computed\n",
      "Step 5: Key insights identified\n",
      "Step 6: Output files generated\n",
      "\n",
      "=== Key Insights ===\n",
      "Top-Performing Region: North (Revenue: 15,000.00)\n",
      "Low-Performing Regions: 2\n",
      "Regions needing attention:\n",
      "  - West: 2,500.00\n",
      "  - South: 500.00\n"
     ]
    }
   ],
   "source": [
    "regional_summary, low_performing = analyze_regional_sales(\"regional_sales.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
